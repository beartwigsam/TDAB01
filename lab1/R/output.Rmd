---
title: "TDAB01 - Laboration 1"
author: "sambl126, johfa688"
date: "18 September 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
setwd("/home/sambl126/TDAB01/TDAB01/lab1/R")
```

## Uppgift 1
### a)
```{r}
v1col = rgb(0, 0, 255, max = 255, alpha = 125, names = "v1-graph")
v2col = rgb(255, 0, 0, max = 255, alpha = 125, names = "v2-graph")

v1.sd <- 4
v1.mean <- 10
v1 <- rnorm(n = 100,   v1.mean, v1.sd)
v2.sd <- 4
v2.mean <- 10
v2 <- rnorm(n = 10000, v2.mean, v2.sd)
hist(v1, probability = TRUE, xlab="Value", col=v1col, main="Histogram of v1 and v2", ylim=c(0, 0.15))
hist(v2, probability = TRUE, xlab="Value", col=v2col, add=TRUE)
legend("topleft", inset=0.02, c("V1", "V2"), fill=c(v1col, v2col), horiz=TRUE, cex=0.8)

# Täthetsfunktion för normalfördelning
v1.pdf <- (1 / sqrt(2 * pi * v1.sd^2)) * exp(-(v1 - v1.mean)^2 / (2 * v1.sd^2))
v2.pdf <- (1 / sqrt(2 * pi * v2.sd^2)) * exp(-(v2 - v2.mean)^2 / (2 * v2.sd^2))
hist(v1.pdf, probability = TRUE, xlab="Probability", 
     col=v1col, main="pdf histogram of v1 and v2", ylim=c(0, 50))
hist(v2.pdf, probability = TRUE, col=v2col, add=TRUE)

legend("topleft", inset=0.02, c("V1", "V2"), fill=c(v1col, v2col), horiz=TRUE, cex=0.8)
```

### b)
Skillnaden är att V2-grafen ser närmare ut som en standard normalfördelning jämfört med V1. Vi ser också i pdf-histogrammet att V2 efterliknar en lenare exponentiell funktion jämfört med V1.

## Uppgift 2
```{r}
x1 = rbinom(n = 10000, size = 1, prob = 0.2)
hist(x1)

x2 = rbinom(10000, 20, 0.1)
hist(x2)

x3 = rbinom(10000, 20, 0.5)
hist(x3)

x4 = rgeom(10000, 0.1)
hist(x4)

x5 = rpois(10000, 10)
hist(x5)

y1 = runif(10000, 0, 1)
hist(y1, breaks = 100)

y2 = rexp(10000, 3)
hist(y2, breaks = 100)

y3 = rgamma(10000, 2, 1)
hist(y3, breaks = 100)

y4 = rt(10000, 3, 0)
hist(y4, breaks = 100)

y5 = rbeta(10000, 0.1, 0.1)
hist(y5, breaks = 100)

y6 = rbeta(10000, 1, 1)
hist(y6, breaks = 100)

y7 = rbeta(10000, 10, 5)
hist(y7, breaks = 100)
```

## Uppgift 3
### a)

```{r}
col1 = rgb(0, 0, 255, max = 255, alpha = 125, names = "v1-graph")
col2 = rgb(255, 0, 0, max = 255, alpha = 125, names = "v2-graph")

x1    = rbinom(n = 1000, size = 10000, prob = 0.001)
x1.dt = dbinom(x = 10000, size = 10000, prob = 0.001)
hist(x1, col = col1, xlim = c(-1,30), breaks = 100)
hist(x1.dt, col = col2, add=TRUE)

x2 = rt(1000, 10000, 0)
hist(x2, col = col2, breaks = 100)

x1.2 = rnorm(1000, mean(x1), sqrt(var(x1)))
hist(x1.2, col = col1, breaks = 100)

```

### b)
#### Binomialfördelning
Binomialfördelningen kan approximeras med en normalfördelning när n är tillräckligt stort.

#### Student-t-fördelning
Student-t-fördelningen närmar sig också en normalfördelning eftersom "svansen" blir mindre med större värde på v.

### c)
Normalfördelningen följer liknande mönster som x1 och x2.


## Uppgift 4

### a)
```{r}
stats = data(faithful)
waiting = faithful[, 2]
hist(waiting, probability = TRUE, breaks = 50, xlim=c(40, 100), ylim=c(0, 0.12))
```

### b)
```{r}
k <- 1:10000
x1 = rbinom(10000, 1, 0.3)
norm1 = rnorm(10000, 15, 3)
norm2 = rnorm(10000, 4, 2)
i = 1
for(x in x1) 
{
  k[i] = sample(x * norm1 + (1 - x) * norm2, 1)
  i = i + 1
}
hist(k, breaks=100)
```

### c)
```{r}
k <- 1:10000
x1 = rbinom(10000, 1, 0.35)
norm1 = rnorm(10000, 54, sqrt(20))
norm2 = rnorm(10000, 79, sqrt(25))
i = 1
for(x in x1) 
{
  k[i] = sample(x * norm1 + (1 - x) * norm2, 1)
  i = i + 1
}
hist(k, breaks=50, probability = TRUE, xlim=c(40, 100), ylim=c(0, 0.12))
```

## Uppgift 5
### a)
```{r}
Y.n = 10
Y.p = 0.1
Y = rbinom(10000, Y.n, Y.p)
Y.d = dbinom(0, Y.n, Y.p)
hist(Y)

n = 0
for(y in Y) 
{
  if(y == 0) {
    n = n + 1
  }
}

print(n)
```

### b)
```{r}
#1
pnorm(0, mean=0, sd=1)
#2
pnorm(1.0, mean=0, sd=1) - pnorm(-1.0, mean=0, sd=1)
#3
1 - pnorm(1.96, mean=0, sd=1)
#4
pbinom(9, 10, 0.1) - pbinom(1, 10, 0.1) # 9 och 1 eftersom det är "mindre än" och "större än" och det är diskreta värden.
#5
pbinom(0, 10, 0.1) - pbinom(-1, 10, 0.1) # -1 för tydlighet
#6
pbinom(10, 10, 0.1) - pbinom(0, 10, 0.1) # Eftersom nu så är det "mindre eller lika med"
```

### c)
```{r}
Y.n = 10
Y.p = 0.1
Y = rbinom(10000, Y.n, Y.p)
X = rnorm(10000, 0, 1)

X.cmf = ecdf(X)
Y.cmf = ecdf(Y)
plot(X.cmf, col="blue")
plot(Y.cmf, col="red", add = TRUE)

#1
X.cmf(0.0)
#2
X.cmf(1.0) - X.cmf(-1.0)
#3
1 - X.cmf(1.96)
#4
Y.cmf(9) - Y.cmf(1) # 9 och 1 eftersom det är "mindre än" och "större än" och det är diskreta värden.
#5
Y.cmf(0)-Y.cmf(-1) # -1 för tydlighet
#6
Y.cmf(10) - Y.cmf(0) # Eftersom nu så är det "mindre eller lika med" etc.
```

## Uppgift 6

```{r}
GS = rbinom(10000, 337, 0.1)
NS.P = runif(10000, 0.02, 0.16)
NS = rbinom(10000, 337, sample(NS.P))

# a)
GS.exp.errors = 0.1 * 337
NS.exp.errors = mean(NS.P) * 337
print(NS.exp.errors)
print(GS.exp.errors)


# b)
NS.cmf = ecdf(NS)
NS.cmf(GS.exp.errors)
plot(NS.cmf, col="blue")

GS.cmf = ecdf(GS)
GS.cmf(GS.exp.errors)
plot(GS.cmf, col="red", add=TRUE)
abline(v=GS.exp.errors, col="grey", lwd=1, lty=2)

# c)
NS.p.50 = 1 - NS.cmf(50)
GS.p.50 = 1 - GS.cmf(50)
print(NS.p.50)
print(GS.p.50)
abline(v=50, col="grey", lwd=1, lty=2)
```

### a)
Nya systemet: 30.43495

Gamla systemet: 33.7

### b)
Det nya systemet ges av det blåa strecket och det gamla systemet ges av det röda. Utifrån grafen så ser vi då att det är upp till ca 60% (0.6) sannolikhet att det nya systemet presterar bättre än det gamla, då 60% 
 av det nya systemets approximerade utfall presterade bättre än det förväntade antalet fel i det gamla systemet.

### c)
Nya systemet: ca 0.096

Gamla systemet: ca 0.0026

Detta vittnar om att det gamla systemet mer sällan presterar riktigt dåligt (enligt antagande), medan
 det nya systemet istället oftare presterar riktigt bra.
 
## Uppgift 7
```{r}
X = runif(100, 0, 1)
Y = runif(100, 0, 1)

villkor <- sqrt(X^2 + Y^2) < 1

# a)
plot(X[villkor], col="red")
plot(Y[villkor], col="blue")

# b)
calcZ <- function(z, n){
  return(4 * (z / n))
}
simXY <- function(b){
  X <- runif(b, 0, 1)
  Y <- runif(b, 0, 1)
  villkor <- sqrt(X^2 + Y^2) < 1
  return(calcZ(length(X[villkor]) + length(Y[villkor]), b))
}

simXY(10000)
simXY(100000)
simXY(1000000)
```

### b)
Vi tror att den närmar sig 2 * pi.

### c)
Oscillationerna verkar avta med fler samplingar d.v.s. differensen mellan talen blir mindre.

### d)
Integralen ger oss: [x^3 / 3](0 till 2) = 8/3 - 0 = 8/3

### e)
Approximationen ges av: 
```{r}
X <- runif(100000, 0, 2)
Y <- runif(100000, 0, 4)
IHat = mean(Y < X^2)
print(IHat * 2 * 4)
```
Vilket är nära 8/3.

## Uppgift 8

### a)
Binomialfördelning:
```{r}
n = 10
p = 0.2
print(n * p)
```

Gamma-fördelning:
```{r}
alpha = 2
beta = 2
print(alpha/beta)
```

### b)
```{r}
pullXBinom <- function(a.a){
  b = vector()
  for(a in a.a) {
    X = rbinom(a, 10, 0.2)
    X.mean = mean(X)
    b = append(b, X.mean)
  }
  return(b)
}

pullYGamma <- function(a.a){
  b = vector()
  for(a in a.a) {
    Y = rgamma(a, 2, 2)
    Y.mean = mean(Y)
    b = append(b, Y.mean)
  }
  return(b)
}

v = 1:9
totalmean = pullXBinom(v * 10)
totalpull = v * 10
totalmean = append(totalmean, pullXBinom(v * 100))
totalpull = append(totalpull, v * 100)
totalmean = append(totalmean, pullXBinom(v * 1000))
totalpull = append(totalpull, v * 1000)
totalmean = append(totalmean, pullXBinom(10000))
totalpull = append(totalpull, 10000)

plot(totalpull, totalmean, type="l", main="binomial")

totalmean2 = pullYGamma(v * 10)
totalpull2 = v * 10
totalmean2 = append(totalmean2, pullYGamma(v * 100))
totalpull2 = append(totalpull2, v * 100)
totalmean2 = append(totalmean2, pullYGamma(v * 1000))
totalpull2 = append(totalpull2, v * 1000)
totalmean2 = append(totalmean2, pullYGamma(10000))
totalpull2 = append(totalpull2, 10000)

plot(totalpull2, totalmean2, type="l", main="gamma")
```

Som vi ser så närmar sig graferna de värden som beräknades i a) för respektive fördelning.

## Uppgift 9

### a)

#### Exponentialfördelning
Väntevärde: lambda^(⁻1) (eller Beta)
Varians:    lambda^(-2) (eller Beta^2)

I detta fall: 10⁻¹ = 1/10 och 10⁻² = 1/100

#### Poissonfördelning
Väntevärde och varians: lambda

I detta fall: 3 och 3.

### b)
Beräkningar för dessa:
```{R}
n       = 10000
rateX   = 10
lambdaY = 3
X = rexp(n, rateX)
Y = rpois(n, lambdaY)

# Väntevärde och varians för X
# Bör vara ~1/10 och ~1/100 respektive.
print(mean(X))
print(var(X))

# Väntevärde och varians i Y
# Bör vara ~3 vardera.
print(mean(Y))
print(var(Y))

```

### c)

#### 1.
E(3) = 3

#### 2.
E(3X + 2) = 3E(X) + 2 = 3*1/10 + 2 = 23/10

#### 3.
E(X + Y) = E(X) + E(Y) = 1/10 + 3 = 31/10

#### 4.
(x := gånger)
E(X x Y) = E(X) x E(Y) = 1/10 x 3 = 3/10

#### 5.
E(3 x X + 2 x Y - 3) = 3/10 + 6 - 3 = 33/10

#### 6.
Var(2 x X - 5) = 2² x Var(X) = 4 x 1/100 = 4/100 = 1/25

#### 7.
Var(X + Y) = Var(X) + Var(Y) = 1/100 + 3 = 301/100

### d)
```{R}
n       = 10000
rateX   = 10
lambdaY = 3
X = rexp(n, rateX)
Y = rpois(n, lambdaY)

# 1.
print(mean(3))
# 2.
print(mean((3 * X) + 2))
# 3.
print(mean(X + Y))
# 4.
print(mean(X * Y))
# 5.
print(mean((3*X) + (2*Y) -3))
# 6.
print(var((2*X)-5))
# 7.
print(var(X + Y))
```


## Uppgift 10

### a)
```{R}
n       = 1000
lambda  = 5
rate    = 1
size    = 10
p       = 0.01

X = rpois(n, lambda)
Y = rexp(n, rate)
Z = rbinom(n, size, p)

hist(X, col="blue", ylim = c(0, 1000))
hist(Y, col="red", add=TRUE)
hist(Z, col="green", add=TRUE)
```

### b)
```{R}
n       = 1000
lambda  = 5
rate    = 1
X       = rpois(n, lambda)
Y       = rexp(n, rate)

# Makes a given number of pulls from Z, where every pull is
#  a mean value of 10 samples from Z.
# These pulls are then returned as a vector.
meanOf10 <- function(pulls, Z) {
  v = vector(length=1000)
  m = 0
  
  for(i in 1:1000) {
    m = 0
    for(j in 1:pulls) {
      m = m + sample(Z, 1)
    }
    m = m/pulls
    v[i] = m
  }
  return(v)
}

Xhat = meanOf10(10, X)
Yhat = meanOf10(10, Y)

hist(Xhat, xlim = c(0, 8), ylim = c(0, 250), col="blue", main = paste("X (blue) and Y (red)"))
hist(Yhat, add=TRUE, col="red")
```

### c)
```{R}
n       = 1000
lambda  = 5
rate    = 1
size    = 10
p       = 0.01

X = rpois(n, lambda)
Y = rexp(n, rate)
Z = rbinom(n, size, p)

# Makes a given number of pulls from Z, where every pull is
#  a mean value of 10 samples from Z.
# These pulls are then returned as a vector.
meanOf10 <- function(pulls, Z) {
  v = vector(length=1000)
  m = 0
  
  for(i in 1:1000) {
    m = 0
    for(j in 1:pulls) {
      m = m + sample(Z, 1)
    }
    m = m/pulls
    v[i] = m
  }
  return(v)
}

X1 = meanOf10(30, X)
X2 = meanOf10(100, X)
X3 = meanOf10(1000, X)
hist(X1, col="blue", ylim = c(0, 250), breaks = 50, main = paste("30 (blue), 100 (cyan) and 1000 (green) pulls from X"))
hist(X2, col="cyan",add = TRUE, breaks = 50)
hist(X3, col="green",add = TRUE, breaks = 10) 

Y1 = meanOf10(30, Y)
Y2 = meanOf10(100, Y)
Y3 = meanOf10(1000, Y)
hist(Y1, col="blue", ylim = c(0, 250), breaks = 50, main = paste("30 (blue), 100 (cyan) and 1000 (green) pulls from Y"))
hist(Y2, col="cyan",add = TRUE, breaks = 50)
hist(Y3, col="green",add = TRUE, breaks = 10)

Z1 = meanOf10(30, Z)
Z2 = meanOf10(100, Z)
Z3 = meanOf10(1000, Z)
hist(Z1, col="blue", ylim = c(0, 250), main = paste("30 (blue), 100 (cyan) and 1000 (green) pulls from Z"))
hist(Z2, col="cyan",add = TRUE)
hist(Z3, col="green",add = TRUE)
```